## Exercise Unit: Handling and Processing IoT Sensor Data with Azure Services

**Learning Objective:**
- Learners will be able to create a database with Azure Cosmos DB, build and deploy an Azure Function to process and store event data, and integrate various Azure services to manage and analyze event data.

**Scenario:**
- You are a developer at a company that needs to handle and process sensor data from IoT devices. You will create an Azure Cosmos DB database to store the sensor data and build an Azure Function that processes this data received from an Event Hub. Your task includes configuring the necessary Azure services, deploying the Azure Function, and ensuring that the system is scalable and loosely coupled.

### Task 1: Set up an Azure Cosmos DB database and a SQL container using Azure CLI
1. **Open the Azure CLI:**
   1. Install the Azure CLI from [here](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli) if not already installed.
   2. Open a terminal or command prompt.

2. **Login to your Azure account:**
   ```sh
   az login
   ```

3. **Create a resource group:**
   ```sh
   az group create --name <resource-group-name> --location <location>
   ```

4. **Create an Azure Cosmos DB account:**
   ```sh
   az cosmosdb create --name <cosmosdb-account-name> --resource-group <resource-group-name> --kind GlobalDocumentDB --locations regionName=<location>
   ```

5. **Create a database in your Cosmos DB account:**
   ```sh
   az cosmosdb sql database create --account-name <cosmosdb-account-name> --resource-group <resource-group-name> --name <database-name>
   ```

6. **Create a SQL container in the database:**
   ```sh
   az cosmosdb sql container create --account-name <cosmosdb-account-name> --resource-group <resource-group-name> --database-name <database-name> --name <container-name> --partition-key-path "/id"
   ```

### Task 2: Create and configure an Azure Function with the necessary storage account and bindings
1. **Create a storage account:**
   ```sh
   az storage account create --name <storage-account-name> --location <location> --resource-group <resource-group-name> --sku Standard_LRS
   ```

2. **Create a function app:**
   ```sh
   az functionapp create --resource-group <resource-group-name> --consumption-plan-location <location> --runtime dotnet --functions-version 3 --name <function-app-name> --storage-account <storage-account-name>
   ```

3. **Add Cosmos DB output binding to the function:**
   1. Navigate to your function app in the Azure portal.
   2. Select **Functions** > **Add** > **HttpTrigger**.
   3. Select **Integration** > **+ Add output** > **Azure Cosmos DB**.
   4. Configure the binding with details for your Cosmos DB account.

### Task 3: Retrieve and store connection strings for the storage account, event hub, and Cosmos DB in the Azure Functions application settings
1. **Retrieve the Cosmos DB connection string:**
   1. Navigate to your Cosmos DB account in the Azure portal.
   2. Select **Keys** and copy the PRIMARY CONNECTION STRING.

2. **Add the connection string to your Function App settings:**
   1. Navigate to your Function App in the Azure portal.
   2. Select **Configuration** > **Application settings** > **+ New application setting**.
   3. Add a new setting with the name `CosmosDBConnection` and paste the copied connection string as the value.

3. **Repeat the above steps to add connection strings for the storage account and event hub.**

### Task 4: Develop the Azure Function using Maven to process sensor data and store it in Cosmos DB
1. **Set up your development environment:**
   1. Install [Maven](https://maven.apache.org/install.html).
   2. Install [Azure Functions Core Tools](https://docs.microsoft.com/en-us/azure/azure-functions/functions-run-local).

2. **Create a new Maven project for Azure Functions:**
   ```sh
   mvn archetype:generate -DarchetypeGroupId=com.microsoft.azure -DarchetypeArtifactId=azure-functions-archetype
   ```

3. **Update the function code to process sensor data:**
   ```java
   @FunctionName("ProcessSensorData")
   public void run(
       @EventHubTrigger(name = "message", eventHubName = "<event-hub-name>", connection = "EventHubConnection") String message,
       @CosmosDBOutput(name = "databaseOutput", databaseName = "<database-name>", collectionName = "<container-name>", connectionStringSetting = "CosmosDBConnection") OutputBinding<String> databaseOutput,
       final ExecutionContext context
   ) {
       context.getLogger().info("Received message: " + message);
       // Add logic to process the message and store it in Cosmos DB
       databaseOutput.setValue(message);
   }
   ```

### Task 5: Test the Azure Function locally to verify its operation
1. **Run your function app locally:**
   ```sh
   mvn clean package
   mvn azure-functions:run
   ```

2. **Trigger the function with sample data:**
   - Use tools like Postman or curl to send HTTP requests to the local function endpoint.

### Task 6: Deploy the Azure Function to Azure using Maven and verify its deployment
1. **Deploy the function to Azure:**
   ```sh
   mvn azure-functions:deploy
   ```

2. **Verify the deployment:**
   - Navigate to your Function App in the Azure portal and check the deployed function.
   - Trigger the function and verify that data is being stored in Cosmos DB.

### Task 7: Monitor the system for successful data processing and scalability
1. **Set up monitoring and alerts:**
   1. Navigate to your Function App in the Azure portal.
   2. Select **Monitor** and configure logs and metrics to monitor function execution.
   3. Set up alerts for any errors or performance issues.

2. **Review and analyze logs:**
   - Use Azure Monitor and Application Insights to review logs and analyze the performance and scalability of your function.

**Practical Tasks:**
1. **Create a new Cosmos DB account and a container to store sensor data.**
2. **Develop and deploy an Azure Function that processes sensor data and stores it in Cosmos DB.**

**Checkpoints:**
1. **Question:** What is the purpose of adding an output binding to the Azure Function?
   - **Answer:** An output binding allows the function to send data to an external service, such as storing processed data in Cosmos DB.
2. **Task:** Verify that your function processes sensor data and stores it correctly in Cosmos DB by checking the stored documents.

**Additional Resources:**
- [Store unstructured data using Azure Cosmos DB and Functions](https://learn.microsoft.com/en-us/azure/azure-functions/functions-integrate-store-unstructured-data-cosmosdb)
- [Azure Cosmos DB design pattern: Event sourcing](https://learn.microsoft.com/en-us/samples/azure-samples/cosmos-db-design-patterns/event-sourcing/)
- [Connect Azure Functions to Azure Cosmos DB using Visual Studio Code](https://learn.microsoft.com/en-us/azure/azure-functions/functions-add-output-binding-cosmos-db-vs-code)
- [Serverless event processing](https://learn.microsoft.com/en-us/azure/architecture/reference-architectures/serverless/event-processing)

**Key Takeaways:**
- Setting up an Azure Cosmos DB database and container is crucial for storing unstructured sensor data.
- Developing and configuring an Azure Function to process and store data involves defining triggers and output bindings.
- Monitoring and ensuring the scalability of the system is important to handle large volumes of sensor data effectively.
